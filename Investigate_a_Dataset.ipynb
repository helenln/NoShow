{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip**: Welcome to the Investigate a Dataset project! You will find tips in quoted sections like this to help organize your approach to your investigation. Before submitting your project, it will be a good idea to go back through your report and remove these sections to make the presentation of your work as tidy as possible. First things first, you might want to double-click this Markdown cell and change the title so that it reflects your dataset and investigation.\n",
    "\n",
    "# Project: Investigate a Dataset (Replace this with something more specific!)\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "> **Tip**: In this section of the report, provide a brief introduction to the dataset you've selected for analysis. At the end of this section, describe the questions that you plan on exploring over the course of the report. Try to build your report around the analysis of at least one dependent variable and three independent variables. If you're not sure what questions to ask, then make sure you familiarize yourself with the dataset, its variables and the dataset context for ideas of what to explore.\n",
    "\n",
    "> If you haven't yet selected and downloaded your data, make sure you do that first before coming back here. In order to work with the data in this workspace, you also need to upload it to the workspace. To do so, click on the jupyter icon in the upper left to be taken back to the workspace directory. There should be an 'Upload' button in the upper right that will let you add your data file(s) to the workspace. You can then click on the .ipynb file name to come back here.\n",
    "\n",
    "I chose to analyze the no show appointments data to determine whether or not patients show up to their appointments. The following are questions I plan on exploring: Which neighborhoods have a higher rate of patients showing up to their appointments, does scholarship affect appointments, and does one gender have more no-shows than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to set up import statements for all of the packages that you\n",
    "#   plan to use.\n",
    "\n",
    "# Remember to include a 'magic word' so that your visualizations are plotted\n",
    "#   inline with the notebook. See this page for more:\n",
    "#   http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "> **Tip**: In this section of the report, you will load in the data, check for cleanliness, and then trim and clean your dataset for analysis. Make sure that you document your steps carefully and justify your cleaning decisions.\n",
    "\n",
    "### General Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data and print out a few lines. Perform operations to inspect data\n",
    "#   types and look for instances of missing or possibly errant data.\n",
    "df = pd.read_csv('data/noshowappointments-kagglev2-may-2016.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Data columns (total 14 columns):\n",
      "PatientId         110527 non-null float64\n",
      "AppointmentID     110527 non-null int64\n",
      "Gender            110527 non-null object\n",
      "ScheduledDay      110527 non-null object\n",
      "AppointmentDay    110527 non-null object\n",
      "Age               110527 non-null int64\n",
      "Neighbourhood     110527 non-null object\n",
      "Scholarship       110527 non-null int64\n",
      "Hipertension      110527 non-null int64\n",
      "Diabetes          110527 non-null int64\n",
      "Alcoholism        110527 non-null int64\n",
      "Handcap           110527 non-null int64\n",
      "SMS_received      110527 non-null int64\n",
      "No-show           110527 non-null object\n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip**: You should _not_ perform too many operations in each cell. Create cells freely to explore your data. One option that you can take with this project is to do a lot of explorations in an initial notebook. These don't have to be organized, but make sure you use enough comments to understand the purpose of each code cell. Then, after you're done with your analysis, create a duplicate notebook where you will trim the excess and organize your steps so that you have a flowing, cohesive report.\n",
    "\n",
    "> **Tip**: Make sure that you keep your reader informed on the steps that you are taking in your investigation. Follow every code cell, or every set of related code cells, with a markdown cell to describe to the reader what was found in the preceding cell(s). Try to make it so that the reader can then understand what they will be seeing in the following cell(s).\n",
    "\n",
    "### Data Cleaning (Replace this with more specific notes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2016-04-29T00:00:00Z\n",
       "1         2016-04-29T00:00:00Z\n",
       "2         2016-04-29T00:00:00Z\n",
       "3         2016-04-29T00:00:00Z\n",
       "4         2016-04-29T00:00:00Z\n",
       "5         2016-04-29T00:00:00Z\n",
       "6         2016-04-29T00:00:00Z\n",
       "7         2016-04-29T00:00:00Z\n",
       "8         2016-04-29T00:00:00Z\n",
       "9         2016-04-29T00:00:00Z\n",
       "10        2016-04-29T00:00:00Z\n",
       "11        2016-04-29T00:00:00Z\n",
       "12        2016-04-29T00:00:00Z\n",
       "13        2016-04-29T00:00:00Z\n",
       "14        2016-04-29T00:00:00Z\n",
       "15        2016-04-29T00:00:00Z\n",
       "16        2016-04-29T00:00:00Z\n",
       "17        2016-04-29T00:00:00Z\n",
       "18        2016-04-29T00:00:00Z\n",
       "19        2016-04-29T00:00:00Z\n",
       "20        2016-04-29T00:00:00Z\n",
       "21        2016-04-29T00:00:00Z\n",
       "22        2016-04-29T00:00:00Z\n",
       "23        2016-04-29T00:00:00Z\n",
       "24        2016-04-29T00:00:00Z\n",
       "25        2016-04-29T00:00:00Z\n",
       "26        2016-04-29T00:00:00Z\n",
       "27        2016-04-29T00:00:00Z\n",
       "28        2016-04-29T00:00:00Z\n",
       "29        2016-04-29T00:00:00Z\n",
       "                  ...         \n",
       "110497    2016-06-01T00:00:00Z\n",
       "110498    2016-06-08T00:00:00Z\n",
       "110499    2016-06-01T00:00:00Z\n",
       "110500    2016-06-08T00:00:00Z\n",
       "110501    2016-06-01T00:00:00Z\n",
       "110502    2016-06-08T00:00:00Z\n",
       "110503    2016-06-01T00:00:00Z\n",
       "110504    2016-06-08T00:00:00Z\n",
       "110505    2016-06-01T00:00:00Z\n",
       "110506    2016-06-01T00:00:00Z\n",
       "110507    2016-06-08T00:00:00Z\n",
       "110508    2016-06-01T00:00:00Z\n",
       "110509    2016-06-08T00:00:00Z\n",
       "110510    2016-06-01T00:00:00Z\n",
       "110511    2016-06-08T00:00:00Z\n",
       "110512    2016-06-08T00:00:00Z\n",
       "110513    2016-06-08T00:00:00Z\n",
       "110514    2016-06-08T00:00:00Z\n",
       "110515    2016-06-08T00:00:00Z\n",
       "110516    2016-06-08T00:00:00Z\n",
       "110517    2016-06-07T00:00:00Z\n",
       "110518    2016-06-07T00:00:00Z\n",
       "110519    2016-06-07T00:00:00Z\n",
       "110520    2016-06-07T00:00:00Z\n",
       "110521    2016-06-07T00:00:00Z\n",
       "110522    2016-06-07T00:00:00Z\n",
       "110523    2016-06-07T00:00:00Z\n",
       "110524    2016-06-07T00:00:00Z\n",
       "110525    2016-06-07T00:00:00Z\n",
       "110526    2016-06-07T00:00:00Z\n",
       "Name: AppointmentDay, Length: 110527, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = df['AppointmentDay']\n",
    "dt = datetime.strptime(date, '%Y/%M/%D %H:%M:%S')\n",
    "month = dt.month\n",
    "hour = dt.hour\n",
    "day_of_week_index = dt.weekday()\n",
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_of_week = days_of_week[day_of_week_index]\n",
    "return (month, hour, day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38687"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After discussing the structure of the data and any problems that need to be\n",
    "#   cleaned, perform those cleaning steps in the second part of this section.\n",
    "df_male = sum(df['Gender'] ==\"M\")\n",
    "df_male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = sum(df['Gender'] ==\"F\")\n",
    "df_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "### Research Question 1 (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n",
    "df_f = sum(df['Gender'] == 'F')\n",
    "df_f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_g(gender):\n",
    "    if df['Gender'] == 'gender' and df['No-show'] == 'Yes':\n",
    "        return sum\n",
    "df_g('F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = sum(df['Gender'] ==\"M\")\n",
    "df_male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2  (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work, you should save a copy of the report in HTML or PDF form. Before exporting your report, check over it to make sure that the flow of the report is complete. You should probably remove all of the \"Tip\" quotes like this one so that the presentation is as tidy as possible. It's also a good idea to look over the project rubric, found on the project submission page at the end of the lesson.\n",
    "\n",
    "> To export the report to the workspace, you should run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the jupyter icon in the upper left). Alternatively, you can download the html report via the **File** > **Download as** submenu and then manually upload it to the workspace directory. Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
